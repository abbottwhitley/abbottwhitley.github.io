---
layout: page
title: About
permalink: /about/
---
Independent Study will focus on visual recognition tasks such as image classification, localization, and detection. The course study is based primarily on the free material made available through Stanford University -  [Convolutional Neural Network for Visual Recognition](http://cs231n.stanford.edu/). 

Course study will cover data driven approaches to discuss deep learning architectures with an emphasis on end-to-end models for image classification. Completion of study will provide opportunity to implement, train, and debug custom neural networks and gain a detailed understanding of research in computer vision. Topics of study provided through the course material have been broken down into 3 separate modules which have been detailed below. 


# Module 0:
- Python, Numpy, and Jupyter Notebooks
- Google Cloud Platform, Google Compute Engine and Google Cloud VM


# Module 1:
- Image Classification: Data-driven Approach, k-Nearest Neighbor, train/val/test splits
	- L1/L2 Distances
	- Hyperparameter Search
	- Cross Validation
- Linear Classification: Support Vector Machine & Softmax
	- Parametric Approach
	- Bias Trick
	- Hinge Loss
	- Cross-Entropy Loss
	- L2 Regularization
- Optimization: Stochastic Gradient Descent
	- Optimization Landscapes
	- Local Search
	- Learning Rate
	- Analytic / Numerical Gradient
- Backpropagation, Intuitions
	- Chain Rule Interpretation
	- Real-Value Circuits
	- Patterns in Gradient Flow
- Neural Networks Part 1: Setting up the Architecture
	- Model of a biological neuron
	- Activation functions
	- Neural Net Architecture
	- Representational Power
- Neural Networks Part 2: Setting up the Data and the Loss
	- Preprocessing
	- Weight Initialization
	- Batch Normalization
	- Regularization, (L2 / dropout)
	- Loss Functions
- Neural Networks Part3: Learning and Evaluation
	- Gradient Checks
	- Sanity Checks
	- Babysitting the learning process
	- Momentum (+nesterov)
	- Second-Order Methods
	- Adagrad / RMSprop
	- Hyperparameter Optimization
	- Model Ensembles


# Module 2: Convolutional Neural Networks
- Convolutional Neural Networks: Architectures, Convolution / Pooling Layers
	- Layers
	- Spatial Arrangement
	- Layer Patterns
	- Layer Sizing Patterns
	- AlexNet / ZFNet / VGGNet Case Studies
	- Computation Consideration
- Understanding and Visualizing Convolutional Neural Networks
	- tSNE Embeddings
	- Deconvnets
	- Data Gradients
	- Fooling ConvNets
	- Human Comparisons
- Transfer Learning and Fine-tuning Convolutional Neural Networks

# Deep Learning Hardware and Software Tools
- Python & Jupyter Notebook
- CPUs, GPUs, TPUs
- PyTorch, Tensor Flow
- Dynamic vs Static Computation Graphs
- Google Compute Engine and Google Cloud VM

# Assignments 
To aid in program study, all [assignments](http://cs231n.stanford.edu/) created under the Stanford CNN course are available through a public [github repository](https://github.com/cs231n/cs231n.github.io). Assignments to be completed are listed as follows.

Assignment #1: Image Classification, kNN, SVM, Softmax, neural Network
Assignment #2: Fully-Connected Nets, Batch Normalization, Dropout, Convolutional Nets 
Assignment #3: Image Captioning with Vanilla RNNs, Image Captioning with LSTMs, Network Visualization, Style Transfer, General Adversarial Netoworks


# Additional Resources

- [Deep Learning (Adaptive computation and Machine learning Series), Ian Goodfellow, Yoshua Bengio, Aaron Courville, 2016](http://www.deeplearningbook.org/)
- [Neural Network and Deep Learning, Michael Nielsen, June 2019](http://neuralnetworksanddeeplearning.com/index.html)
